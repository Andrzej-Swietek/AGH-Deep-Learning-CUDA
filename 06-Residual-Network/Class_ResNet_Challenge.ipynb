{"cells":[{"cell_type":"markdown","id":"b0aa8f90-a82c-4c5f-85cb-9d39fe812068","metadata":{"id":"b0aa8f90-a82c-4c5f-85cb-9d39fe812068"},"source":["## Res-NET Challenge"]},{"cell_type":"markdown","id":"f4886a3b-deb5-4fc2-8ed1-b319af4c3532","metadata":{"id":"f4886a3b-deb5-4fc2-8ed1-b319af4c3532"},"source":["# An interesting cutting-edge model for computer vision applications\n","\n","---\n","\n","\n","\n","So far you've learned about the difference between gradient descent (i.e. a batch size equal to the full dataset) and mini-batch stochastic gradient descent (the batch size is smaller than the full dataset, usually much smaller). You've seen that smaller batch sizes add noise to the optimization process, which can help with avoiding getting trapped in local minima or slowed down at a saddle point. A smaller batch size will also mean running back-propagation and updating the gradients more times per epoch (taking more steps).\n","\n","**In this lab you'll be experimenting with batch size on a more complex dataset and model. You will see the effect of batch size on GPU performance, as well as on the accuracy of training**."]},{"cell_type":"markdown","id":"16ac43b0-220b-49be-aeeb-2e9385404312","metadata":{"id":"16ac43b0-220b-49be-aeeb-2e9385404312"},"source":["## The Fashion-MNIST Dataset\n","\n","The [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) is a response to the traditional MNIST dataset, which is often referred to as the \"hello world\" of machine learning. The original MNIST dataset consists of 60,000 pictures of handwritten digits, 0-9. One of the downsides of this dataset is its simplicity. Good performance of a model on the dataset does not indicate that the model will perform well on a more complicated set of images.\n","\n","The **Fashion-MNIST** dataset was created to be a moderately more complex image classification challenge. It follows the same format as the original MNIST set, with 10 categories and 60,000 images, each 28x28 pixels (plus 10,000 testing images). We'll be training on this dataset for this exercise, as well as for the next labs where we'll introduce training with multiple GPUs.\n"]},{"cell_type":"markdown","id":"d461e540-2e10-47b2-b7a2-51c7f24012b0","metadata":{"id":"d461e540-2e10-47b2-b7a2-51c7f24012b0"},"source":["## The Wide ResNet Model\n","\n","We'll be using a Wide Residual Network to train on this dataset, which is a convolutional neural network proven to perform very well in image classification challenges. Feel free to take some time to learn more about [wide residual networks](https://arxiv.org/abs/1605.07146), the original [residual networks](https://arxiv.org/abs/1512.03385) they are based on, or about [convolutional neural networks](https://developer.nvidia.com/discover/convolutional-neural-network) in general.\n","\n","![wideresnet](./images/wideresnet.png)\n","\n","In the early days of CNNs, the community drove towards very deep models (many tens or hundreds of layers), but as computing power advanced and algorithms improved, in particular after the idea of the residual block was demonstrated, it became more desirable to swing back towards shallower networks with wider layers, which was the primary innovation of the WideResNet family of models. The WideResNet-16-10 we will use below can achieve with O(10 million) parameters accuracy that is competitive with much deeper networks with more parameters."]},{"cell_type":"markdown","id":"c8c761fd-ec03-471b-89cf-906d550a99ca","metadata":{"id":"c8c761fd-ec03-471b-89cf-906d550a99ca"},"source":["## Training our Model\n","\n","We'll start by running training on the existing dataset with default hyperparameters. Please take a few minutes to look through `fashion_mnist.py`, and get familiar with the training. We're using PyTorch for this training, but the takeaways of these exercises should translate to other frameworks.\n","\n","Notice that we're only training on 1/5 of the dataset (12,000 images) for this exercise. We're doing this to keep epoch times short so that we can run quick experiments and see the effects of batch size. When we start introducing multiple GPUs to speed up the training, we'll use the entire dataset.\n","\n","**Once you have a good sense of the code, execute the cell below to run a few epochs. Pay attention to the validation accuracy, validation loss, and epoch time**."]},{"cell_type":"code","source":["# mount your g-drive on local system\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ZpH6e5SeL297","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714488861174,"user_tz":-120,"elapsed":19386,"user":{"displayName":"Andrzej ?wi?tek","userId":"12388722673368553978"}},"outputId":"9c20d5ac-7df8-4d98-aa1c-ffeff1b06654"},"id":"ZpH6e5SeL297","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# copy from your drive to local modify this!!\n","!cp /content/drive/MyDrive/Colab Notebooks/Class_Res_Net_Challenge-MNIST.py /content/."],"metadata":{"id":"24aJ4koAMVyn"},"id":"24aJ4koAMVyn","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":15,"id":"137ac986-d161-4b95-aeb9-b786a1dc9213","metadata":{"id":"137ac986-d161-4b95-aeb9-b786a1dc9213","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714493548035,"user_tz":-120,"elapsed":5336,"user":{"displayName":"Andrzej ?wi?tek","userId":"12388722673368553978"}},"outputId":"49dfccde-7cf7-4b9f-d0c4-32648cd48ac6"},"outputs":[{"output_type":"stream","name":"stdout","text":["==> Running main part of our training\n","==> There is no CUDA capable GPU device here!\n","sh: 1: nvidia-smi: not found\n","Traceback (most recent call last):\n","  File \"/content/Class_Res_Net_Challenge-MNIST.py\", line 208, in <module>\n","    train(model, optimizer, train_loader, loss_fn, device)\n","  File \"/content/Class_Res_Net_Challenge-MNIST.py\", line 122, in train\n","    outputs = model(images)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/Class_Res_Net_Challenge-MNIST.py\", line 100, in forward\n","    out = self.block1(out)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/Class_Res_Net_Challenge-MNIST.py\", line 66, in forward\n","    out = self.layer2(out)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/Class_Res_Net_Challenge-MNIST.py\", line 43, in forward\n","    out = self.cbr(x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","RuntimeError: Given groups=1, weight of size [160, 160, 3, 3], expected input[32, 16, 28, 28] to have 160 channels, but got 16 channels instead\n"]}],"source":["!python Class_Res_Net_Challenge-MNIST.py --epochs 5"]},{"cell_type":"code","source":["!cp *.py \"/content/drive/MyDrive/Colab Notebooks/\""],"metadata":{"id":"DXLt_eyor_rL","executionInfo":{"status":"ok","timestamp":1714493553295,"user_tz":-120,"elapsed":241,"user":{"displayName":"Andrzej ?wi?tek","userId":"12388722673368553978"}}},"id":"DXLt_eyor_rL","execution_count":16,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"64nOGttduWDV"},"id":"64nOGttduWDV","execution_count":null,"outputs":[]}],"metadata":{"jupytext":{"formats":"ipynb"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"provenance":[{"file_id":"14ItVlycnrK12jF6P1ITozmYGuDVkvCrZ","timestamp":1681764422550}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}